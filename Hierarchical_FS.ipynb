{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import copy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pulp as pulp\n",
    "from scipy import stats\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import grid_search\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.metrics import accuracy_score,recall_score\n",
    "from random import randrange"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strToBin(lst):\n",
    "    \"\"\"\n",
    "        Convert a list of str into binary\n",
    "        Input: e.g. ['1', '0']\n",
    "        Output: e.g. [1, 0]\n",
    "    \"\"\"\n",
    "    for i in range(len(lst)):\n",
    "        lst[i]=eval(lst[i])\n",
    "    return lst\n",
    "\n",
    "def CalcIV(x,y):\n",
    "    \"\"\"\n",
    "    Calculate the information gain between two columns of binary data\n",
    "    \n",
    "    \"\"\"\n",
    "    N_0  = np.sum(y==0)\n",
    "    if N_0==0:\n",
    "        N_0=1      \n",
    "    N_1 = np.sum(y==1)\n",
    "    if N_1==0:\n",
    "        N_1=1     \n",
    "    N_0_group = np.zeros(2)\n",
    "    N_1_group = np.zeros(2)\n",
    "    \n",
    "    # +1 to avoid dividing by 0\n",
    "    for i in range(2):\n",
    "        N_0_group[i] = len(y[(x == i) & (y == 0)])\n",
    "        if N_0_group[i]==0:\n",
    "            N_0_group[i]=1\n",
    "        N_1_group[i] = len(y[(x == i) & (y == 1)])\n",
    "        if N_1_group[i]==0:\n",
    "            N_1_group[i]=1  \n",
    "    iv = np.sum((N_0_group/N_0 - N_1_group/N_1) * np.log((N_0_group/N_0)/(N_1_group/N_1)))  \n",
    "    return iv\n",
    "\n",
    "def spe_score(y_true,y_pred):\n",
    "    \"\"\"\n",
    "    Calculate the specificity score\n",
    "    \"\"\"\n",
    "    N_neg = sum(y_true==0)\n",
    "    TN = sum((y_true|y_pred)==0)\n",
    "    return 1.*TN/N_neg\n",
    "\n",
    "def getMean(data):\n",
    "    meanValue = np.round(np.mean(data),3)\n",
    "    return meanValue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataInitialize(file):\n",
    "    \"\"\"\n",
    "    Initialize the data file\n",
    "    Input:\n",
    "        file: name of the data file, i.e. Worm/CE-BP.txt\n",
    "    Outputs:\n",
    "        x: data\n",
    "        y: labels\n",
    "        features: names of features\n",
    "    \"\"\"\n",
    "    data_file = 'Datasets/GeneratedDatasets/ExperimentalDatasets/' + file\n",
    "    with open(data_file,'r') as f:\n",
    "        lines = f.readlines()\n",
    "    y = np.array(strToBin(lines[-1].split(',')[1:-1]))\n",
    "    x = np.zeros((len(y),len(lines)-2))\n",
    "    features = []\n",
    "    for i,line in enumerate(lines[1:-1]):\n",
    "        features.append(line.split(',')[0])\n",
    "        x[:,i] =  np.array(strToBin(line.split(',')[1:-1])) \n",
    "    return x, y, features\n",
    "\n",
    "def pathInitialize(file,features):\n",
    "    \"\"\"\n",
    "    Initialize the path file\n",
    "    Inputs:\n",
    "        file: name of the path file, i.e. Worm/CE-Path-BP.txt\n",
    "    Outputs:\n",
    "        allPath: list of distinct longest paths\n",
    "        parDict: dictionary of {feature: [parents]}, used in SHSEL method\n",
    "    \"\"\"\n",
    "    path_file = 'Datasets/GeneratedDatasets/GOPath/' + file.split('-')[0] + '-Path-' + file.split('-')[1]\n",
    "    allPath = []\n",
    "    with open(path_file,'r') as f:\n",
    "        line = f.readline()\n",
    "        while line:\n",
    "            path = line.split(',')[:-1]\n",
    "            allPath.append(path)\n",
    "            line = f.readline()\n",
    "    parDict = dict()\n",
    "    for f in features:\n",
    "        parDict[f] = set()\n",
    "    for path in allPath:\n",
    "        for i,node in enumerate(path):\n",
    "            if i > 0:\n",
    "                parDict[node].add(path[i-1])\n",
    "    for l in parDict:\n",
    "        parDict[l] = list(parDict[l])\n",
    "    return allPath, parDict\n",
    "\n",
    "def randomSplit(x,y,features, frac=0.8):\n",
    "    \"\"\"\n",
    "    Random Train/test data split, then calculate IG for each feature in training set\n",
    "    Inputs:\n",
    "        x: original data\n",
    "        y: original labels\n",
    "        features: names of features\n",
    "        frac: train-test split ratio\n",
    "    Outputs:\n",
    "        x_train: training data\n",
    "        x_test: testing data\n",
    "        y_train: training labels\n",
    "        y_test: testing labels\n",
    "        IVdict: dictionary of {feature:IG}\n",
    "    \"\"\"\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=1-frac)\n",
    "    IVdict = dict()\n",
    "    for i,feature in enumerate(features):\n",
    "        IVdict[feature] = CalcIV(x_train[:,i], y_train)\n",
    "    return x_train, x_test, y_train, y_test, IVdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_model(clf, X_train, y_train, X_test, y_test):\n",
    "    \"\"\"\n",
    "    Calculate the model metrics GMean\n",
    "    Inputs:\n",
    "        clf: type of classifier\n",
    "        X_train: training data (numpy matrix)\n",
    "        X_test: test data (numpy array)\n",
    "        y_train: training labels (numpy matrix)\n",
    "        y_test: test labels (numpy array)\n",
    "    \"\"\"\n",
    "    # Fit a model by providing X and y from training set\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_test_pred = clf.predict(X_test)\n",
    "    sen = np.round(recall_score(y_test, y_test_pred),3)\n",
    "    spe = np.round(spe_score(y_test, y_test_pred),3)\n",
    "    gm = np.round(1.*np.sqrt(sen*spe),3)\n",
    "    return gm\n",
    "\n",
    "def modeling(x_train, x_test, y_train, y_test):\n",
    "    \"\"\"\n",
    "    Calculate the metrics GMean(sqrt(sen*spe)) of Naive Bayes classifier plus 5-fold cross validation\n",
    "    Inputs:\n",
    "        x_train: training data (numpy matrix)\n",
    "        x_test: test data (numpy array)\n",
    "        y_train: training labels (numpy matrix)\n",
    "        y_test: test labels (numpy array)\n",
    "    \"\"\"\n",
    "    bnb = BernoulliNB()\n",
    "    clf = grid_search.GridSearchCV(bnb, [{'alpha':[1]}], cv=10, scoring='roc_auc')\n",
    "    gm_nb = train_test_model(clf, x_train, y_train, x_test, y_test)\n",
    "    return gm_nb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## No Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NOFS(x_train, x_test, y_train, y_test):\n",
    "    \"\"\"\n",
    "    Complete feature set, without feature selection\n",
    "    \"\"\"\n",
    "    gm = modeling(x_train,x_test,y_train,y_test)\n",
    "    return gm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ReliefF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distanceNorm(Norm,D_value):\n",
    "    # Norm for distance\n",
    "    if Norm == 1:\n",
    "        counter = np.absolute(D_value)\n",
    "        counter = np.sum(counter)\n",
    "    elif Norm == 2:\n",
    "        counter = np.power(D_value,2)\n",
    "        counter = np.sum(counter)\n",
    "        counter = np.sqrt(counter)\n",
    "    else:\n",
    "        counter = np.absolute(D_value)\n",
    "        counter = np.max(counter)\n",
    "    return counter\n",
    "\n",
    "def fit(features,labels,iter_ratio,k,norm):\n",
    "    # initialization\n",
    "    (n_samples,n_features) = np.shape(features)\n",
    "    distance = np.zeros((n_samples,n_samples))\n",
    "    weight = np.zeros(n_features)\n",
    "    labels = list(map(int,labels))\n",
    "\n",
    "    # compute distance\n",
    "    for index_i in range(n_samples):\n",
    "        for index_j in range(index_i+1,n_samples):\n",
    "            D_value = features[index_i] - features[index_j]\n",
    "            distance[index_i,index_j] = distanceNorm(norm,D_value)\n",
    "    distance += distance.T\n",
    "\n",
    "    # start iteration\n",
    "    for iter_num in range(int(iter_ratio*n_samples)):\n",
    "        # random extract a sample\n",
    "        index_i = randrange(0,n_samples,1)\n",
    "        self_features = features[index_i]\n",
    "\n",
    "        # initialization\n",
    "        nearHit = []\n",
    "        nearMiss = dict()\n",
    "        n_labels = list(set(labels))\n",
    "        termination = np.zeros(len(n_labels))\n",
    "        for label in n_labels:\n",
    "            nearMiss[label] = []\n",
    "        distance_sort = []\n",
    "\n",
    "\n",
    "        # search for nearHit and nearMiss\n",
    "        distance[index_i,index_i] = np.max(distance[index_i])\t\t# filter self-distance \n",
    "        for index in range(n_samples):\n",
    "            distance_sort.append([distance[index_i,index],index,labels[index]])\n",
    "\n",
    "        distance_sort.sort(key = lambda x:x[0])\n",
    "\n",
    "        for index in range(n_samples):\n",
    "            # search nearHit\n",
    "            if distance_sort[index][2] == labels[index_i]:\n",
    "                if len(nearHit) < k:\n",
    "                    nearHit.append(features[distance_sort[index][1]])\n",
    "                else:\n",
    "                    termination[distance_sort[index][2]] = 1\n",
    "            # search nearMiss\n",
    "            elif distance_sort[index][2] != labels[index_i]:\n",
    "                if len(nearMiss[distance_sort[index][2]]) < k:\n",
    "                    nearMiss[distance_sort[index][2]].append(features[distance_sort[index][1]])\n",
    "                else:\n",
    "                    termination[distance_sort[index][2]] = 1\n",
    "            if len(list(termination)) == 0:\n",
    "                break;\n",
    "\n",
    "        # update weight\n",
    "        nearHit_term = np.zeros(n_features)\n",
    "        for x in nearHit:\n",
    "            nearHit += np.abs(np.power(self_features - x,2))\n",
    "        nearMiss_term = np.zeros((len(list(set(labels))),n_features))\n",
    "        for index,label in enumerate(nearMiss.keys()):\n",
    "            for x in nearMiss[label]:\n",
    "                nearMiss_term[index] += np.abs(np.power(self_features - x,2))\n",
    "            weight += nearMiss_term[index]/(k*len(nearMiss.keys()))\n",
    "        weight -= nearHit_term/k\n",
    "\n",
    "    return weight/(iter_ratio*n_samples)\n",
    "\n",
    "def ReliefF(x_train, x_test, y_train, y_test, iter_ratio=10, k=3, norm=2):\n",
    "    \"\"\"\n",
    "    'Flat' feature selection method Relief\n",
    "    \"\"\"\n",
    "    weight = fit(x_train, y_train, iter_ratio, k, norm)\n",
    "    x_train_permute = np.random.permutation(x_train)\n",
    "    weight_permute = fit(x_train_permute, y_train, iter_ratio, k, norm)\n",
    "        \n",
    "    removed_idx = []\n",
    "    for i in range(len(weight)):\n",
    "        if weight[i]<=weight_permute[i]:\n",
    "            removed_idx.append(i)\n",
    "\n",
    "    x_train_rf = np.delete(x_train,removed_idx,1)\n",
    "    x_test_rf = np.delete(x_test,removed_idx,1)\n",
    "    \n",
    "    # Modeling\n",
    "    gm = modeling(x_train_rf,x_test_rf,y_train,y_test)\n",
    "    return x_train_rf.shape[1],gm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GTD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GTD(x_train, x_test, y_train, y_test,features,allPath,IVdict):\n",
    "    \"\"\"\n",
    "    Greedy based top-down method\n",
    "    \"\"\"\n",
    "    features_after = []\n",
    "    for path in allPath:\n",
    "        maxIV = 0\n",
    "        feature_select = None\n",
    "        for feature in path:\n",
    "            if IVdict[feature] > maxIV:\n",
    "                maxIV = IVdict[feature]\n",
    "                feature_select = feature\n",
    "        features_after.append(feature)\n",
    "    \n",
    "    features_removed = []\n",
    "    for i,feature in enumerate(features):\n",
    "        if feature not in features_after:\n",
    "            features_removed.append(i)\n",
    "            \n",
    "    x_train_gtd = np.delete(x_train,features_removed,1)\n",
    "    x_test_gtd = np.delete(x_test,features_removed,1)\n",
    "    \n",
    "    # Modeling\n",
    "    gm = modeling(x_train_gtd,x_test_gtd,y_train,y_test)\n",
    "    return x_train_gtd.shape[1],gm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SHSEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shselFS(x_train, y_train, F, H, parDict, IVdict, t):\n",
    "    \"\"\"\n",
    "    Hierarchical Feature Selection Algorithm SHSEL\n",
    "    Inputs: \n",
    "        x_train: training data\n",
    "        y_train: training labels\n",
    "        F: names of all features\n",
    "        H: all longest paths in the feature hierarchy\n",
    "        parDict: dictionary of {feature: [parents]}\n",
    "        IVdict: dictionary of {feature:IG}\n",
    "        t: similarity threshold\n",
    "    Outputs:\n",
    "        features_after: selected features\n",
    "    \"\"\"\n",
    "    sim_func = lambda f1,f2: 1 - np.abs(IVdict[f1] - IVdict[f2])\n",
    "    #Algoritm 1: initSHSEL\n",
    "    for f in parDict:\n",
    "        if f in F:\n",
    "            for d in parDict[f]:\n",
    "                if d in F:\n",
    "                    sim = sim_func(f, d)\n",
    "                    if sim >= t:\n",
    "                        F[F.index(f)] = ''\n",
    "                        break\n",
    "     \n",
    "    #Algorithm 2: pruneSHSEL\n",
    "    features_after = set()\n",
    "    for path in H:\n",
    "        nodes = []\n",
    "        IVs = []\n",
    "        for node in path:\n",
    "            if node in F:\n",
    "                nodes.append(node)\n",
    "                IVs.append(IVdict[node])\n",
    "        avg = np.mean(IVs)\n",
    "        for i,name in enumerate(nodes):\n",
    "            if IVs[i] >= avg:\n",
    "                features_after.add(node)\n",
    "    features_after = list(features_after)\n",
    "    return features_after\n",
    "\n",
    "def SHSEL(x_train, x_test, y_train, y_test, features, allPath, parDict, IVdict, t=0.999):\n",
    "    features_after = shselFS(x_train, y_train, features, allPath, parDict, IVdict, t)\n",
    "    features_removed = []\n",
    "    for i,feature in enumerate(features):\n",
    "        if feature not in features_after:\n",
    "            features_removed.append(i)\n",
    "            \n",
    "    x_train_shsel = np.delete(x_train,features_removed,1)\n",
    "    x_test_shsel = np.delete(x_test,features_removed,1)\n",
    "    \n",
    "    # Modeling\n",
    "    gms = modeling(x_train_shsel,x_test_shsel,y_train,y_test)\n",
    "    return x_train_shsel.shape[1], gms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ILP Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preFiltering(x_train, x_test, y_train, y_test, features, allPath, IVdict):\n",
    "    \"\"\"\n",
    "    Pre-filtering features by removing those that has a lower relevance score than its 'dummy twin'\n",
    "    Inputs: \n",
    "        x_train: training data\n",
    "        x_test: testing data\n",
    "        y_train: training labels\n",
    "        y_test: testing labels\n",
    "        features: list of all features\n",
    "        allPath: list of all paths\n",
    "        IVdict: dictionary of {feature:IG}\n",
    "    Outputs:\n",
    "        x_train: training data\n",
    "        x_test: testing data\n",
    "        features: list of all features\n",
    "        allPath: list of all paths\n",
    "        ancDict: Dictionary of {feature: [ancestors]}, used in ILP method\n",
    "        IVdict: dictionary of {feature:IG}\n",
    "    \"\"\"\n",
    "    # Define the relevance function\n",
    "    rel_func = lambda x,y: CalcIV(x,y) \n",
    "    \n",
    "    removed_idx = []\n",
    "    removed_features = []\n",
    "    iv_permutes = []\n",
    "    for i in range(x_train.shape[1]):\n",
    "        iv = rel_func(x_train[:,i],y_train)\n",
    "        # Randomly permute each feature 10 times\n",
    "        for _ in range(10):\n",
    "            # Each time calculate the IG of the permuted 'twin'\n",
    "            x_train_permute = np.random.permutation(x_train)\n",
    "            iv_permutes.append(rel_func(x_train_permute[:,i],y_train))\n",
    "        # Remove unqualified features\n",
    "        if iv <= np.median(iv_permutes):\n",
    "            removed_idx.append(i)\n",
    "            removed_features.append(features[i])\n",
    "            \n",
    "    for idx in removed_idx:\n",
    "        features[idx] = ''\n",
    "    while '' in features:\n",
    "        features.remove('')\n",
    "    x_train = np.delete(x_train,removed_idx,1)\n",
    "    x_test = np.delete(x_test,removed_idx,1)\n",
    "\n",
    "    for i,path in enumerate(allPath):\n",
    "        for j,feature in enumerate(path):\n",
    "            if feature not in features:\n",
    "                allPath[i][j] = ''\n",
    "        while '' in path:\n",
    "            path.remove('')\n",
    "        if len(path)<=1:\n",
    "            allPath[i] = ''\n",
    "    while '' in allPath:\n",
    "        allPath.remove('')\n",
    "    \n",
    "    ancDict = dict()\n",
    "    for f in features:\n",
    "        ancDict[f] = set()\n",
    "    for path in allPath:\n",
    "        for i,node in enumerate(path):\n",
    "            ancDict[node].update(path[:i])\n",
    "    for l in ancDict:\n",
    "        ancDict[l] = list(ancDict[l])\n",
    "    \n",
    "    for f in removed_features:\n",
    "        IVdict.pop(f)\n",
    "    return x_train,x_test,features,allPath,ancDict,IVdict\n",
    "\n",
    "def findRel(x_train, y_train, features, allPath, ancDict, IVdict):\n",
    "    \"\"\"\n",
    "    Calculate all relevance used in ILP method, i.e. labels' relevance and pairwise relevance\n",
    "    Inputs:\n",
    "        x_train: training data\n",
    "        y_train: training labels\n",
    "        features: list of all features\n",
    "        allPath: list of all paths\n",
    "        ancDict: Dictionary of {feature: [ancestors]}, used in ILP method\n",
    "        IVdict: dictionary of {feature:IG}\n",
    "    Outputs:\n",
    "        features_rel: labels' relevance of all features\n",
    "        features_depth: depths of all features\n",
    "        pair_names: names of all child-ancestor pairs\n",
    "        pair_rel: all pairwise relevance between features and ancestors\n",
    "    \"\"\"\n",
    "    # Pairwise relevance calculation function\n",
    "    sim_func = lambda f1,f2: CalcIV(x_train[:,features.index(f1)], x_train[:,features.index(f2)])\n",
    "    \n",
    "    # Calculate labels' relevance\n",
    "    features_rel = []\n",
    "    for feature in features:\n",
    "        features_rel.append(IVdict[feature])\n",
    "    \n",
    "    # Calculate depths\n",
    "    features_depth = []\n",
    "    depth = dict()\n",
    "    for f in features:\n",
    "        depth[f] = []\n",
    "    for path in allPath:\n",
    "        for i, f in enumerate(path):\n",
    "            depth[f].append(i)\n",
    "    for f in features:\n",
    "        if depth[f]==[]:\n",
    "            features_depth.append(0)\n",
    "        else:\n",
    "            features_depth.append(np.mean(depth[f]))\n",
    "    \n",
    "    # Calculate pairwise relevance\n",
    "    pair_names = []\n",
    "    pair_rel = []\n",
    "    for l in ancDict:\n",
    "        for d in ancDict[l]:\n",
    "            if l in features and d in features:\n",
    "                pair_names.append((l,d))\n",
    "                pair_rel.append(sim_func(l,d))\n",
    "    return features_rel, features_depth, pair_names, pair_rel\n",
    "\n",
    "def ilpFS(features, features_rel, features_depth, pair_names, pair_rel, lam, k):\n",
    "    \"\"\"\n",
    "    Solve the ILP problem with Pulp\n",
    "    Inputs:\n",
    "        features: list of all features\n",
    "        features_rel: list of relevance of each feature and its label\n",
    "        pair_names: list of the names of feature-feature pairs: like [('GO:00001', 'GO:00002'), ('GO:00003', 'GO:00004')]\n",
    "        pair_rel: list of relevance values of feature-feature pairs\n",
    "        lam: the lambda value\n",
    "        k: maximum number of features selected\n",
    "    Output:\n",
    "        features_removed: indexes of features that are removed\n",
    "    \"\"\"\n",
    "    # Define an optimization problem\n",
    "    prob = pulp.LpProblem('LP1' , pulp.LpMaximize)\n",
    "    \n",
    "    # unknown variables w's and z's\n",
    "    ws = [pulp.LpVariable('W%d'%i , lowBound = 0 , upBound=1, cat = pulp.LpInteger) for i in range(0 , len(features_rel))]\n",
    "    zs = [pulp.LpVariable('Z%d'%i , lowBound = 0 , upBound=1, cat = pulp.LpInteger) for i in range(0 , len(pair_rel))]\n",
    "    \n",
    "    # Objective Function\n",
    "    objective = sum([features_rel[i]*ws[i]/(features_depth[i] + 1e-3) for i in range(len(features_rel))])\\\n",
    "                - lam * sum([ pair_rel[i]*zs[i] for i in range(len(pair_rel)) ])\n",
    "    prob += objective\n",
    "    \n",
    "    # Constraints\n",
    "    for i,pair in enumerate(pair_names):\n",
    "        idx1 = features.index(pair[0])\n",
    "        idx2 = features.index(pair[1])\n",
    "        prob += (ws[idx1] + ws[idx2] - zs[i]) <= 1\n",
    "        prob += (-ws[idx1] - ws[idx2] + 2*zs[i]) <= 0\n",
    "    \n",
    "    # Restrict the maximum number of features selected\n",
    "    prob += sum(ws) <= k\n",
    "    \n",
    "    # Solve the problem\n",
    "    prob.solve()\n",
    "    \n",
    "    features_removed = []\n",
    "    for v in prob.variables()[:len(features)]:\n",
    "        if v.varValue==0:\n",
    "            features_removed.append(eval(v.name[1:]))\n",
    "    return features_removed\n",
    "\n",
    "def ILP(x_train, x_test, y_train, y_test, features, allPath, IVdict, k=10000, lam=0.01):\n",
    "    # pre-filtering\n",
    "    x_train, x_test, features, allPath, ancDict, IVdict = preFiltering(x_train, x_test, y_train, y_test, features, allPath, IVdict)\n",
    "    \n",
    "    # Child-ancestors ILP\n",
    "    features_rel, features_depth, pair_names, pair_rel = findRel(x_train, y_train, features, allPath, ancDict, IVdict)\n",
    "    features_removed = ilpFS(features, features_rel, features_depth, pair_names, pair_rel, lam, k)\n",
    "    x_train = np.delete(x_train,features_removed,1)\n",
    "    x_test = np.delete(x_test,features_removed,1)\n",
    "\n",
    "    # Modeling\n",
    "    gm = modeling(x_train, x_test, y_train, y_test)\n",
    "    return x_train.shape[1], gm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithms Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def exp(datasets, freq=20):\n",
    "    \"\"\"\n",
    "    For each dataset, randomly split it into train/test sets 20 times, and compute an average modeling score.\n",
    "    \"\"\"\n",
    "    nofsGM = []\n",
    "    rfN = []\n",
    "    rfGM = []\n",
    "    gtdN = []\n",
    "    gtdGM = []\n",
    "    shselN = []\n",
    "    shselGM = []\n",
    "    ilpN = []\n",
    "    ilpGM = []\n",
    "    ilpGM2 = []\n",
    "    for dataset in datasets:\n",
    "        print(dataset)\n",
    "        x, y, features = dataInitialize(dataset)\n",
    "        allPath, parDict = pathInitialize(dataset,features)\n",
    "        nogm, rfgm, gtdgm, shgm, ilpgm, ilpgm2 = [], [], [], [], [], []\n",
    "        rfn, gtdn, shn, ilpn = [], [], [], []\n",
    "        for i in range(freq):\n",
    "            print(i)\n",
    "            x_train, x_test, y_train, y_test, IVdict = randomSplit(x,y,features)\n",
    "            data = copy.deepcopy((x_train, x_test, y_train, y_test, features, allPath, IVdict))\n",
    "            \n",
    "            # No Feature selection\n",
    "            gm = NOFS(x_train, x_test, y_train, y_test)\n",
    "            nogm.append(gm)\n",
    "            \n",
    "            # ReliefF\n",
    "            n,gm = ReliefF(x_train, x_test, y_train, y_test)\n",
    "            rfn.append(n)\n",
    "            rfgm.append(gm)\n",
    "\n",
    "            # GTD\n",
    "            n,gm = GTD(x_train, x_test, y_train, y_test, features, allPath, IVdict)\n",
    "            gtdn.append(n)\n",
    "            gtdgm.append(gm)\n",
    "            x_train, x_test, y_train, y_test, features, allPath, IVdict = copy.deepcopy(data)\n",
    "            \n",
    "            # SHSEL\n",
    "            nshsel, gm = SHSEL(x_train, x_test, y_train, y_test, features, allPath, parDict, IVdict)\n",
    "            shn.append(nshsel)\n",
    "            shgm.append(gm)\n",
    "            x_train, x_test, y_train, y_test, features, allPath, IVdict = copy.deepcopy(data)\n",
    "\n",
    "            # ILP\n",
    "            n, gm = ILP(x_train, x_test, y_train, y_test, features, allPath, IVdict)\n",
    "            ilpn.append(n)\n",
    "            ilpgm.append(gm)\n",
    "            x_train, x_test, y_train, y_test, features, allPath, IVdict = copy.deepcopy(data)\n",
    "            \n",
    "            # ILP-same number of features as SHSEL\n",
    "            n, gm = ILP(x_train, x_test, y_train, y_test, features, allPath, IVdict, k=nshsel)\n",
    "            ilpgm2.append(gm)\n",
    "            x_train, x_test, y_train, y_test, features, allPath, IVdict = copy.deepcopy(data)\n",
    "            \n",
    "        nofsGM.append(getMean(nogm))\n",
    "        rfN.append(getMean(rfn))\n",
    "        rfGM.append(getMean(rfgm))\n",
    "        gtdN.append(getMean(gtdn))\n",
    "        gtdGM.append(getMean(gtdgm))\n",
    "        shselN.append(getMean(shn))\n",
    "        shselGM.append(getMean(shgm))\n",
    "        ilpN.append(getMean(ilpn))\n",
    "        ilpGM.append(getMean(ilpgm))\n",
    "        ilpGM2.append(getMean(ilpgm2))\n",
    "        \n",
    "    return (nofsGM, rfN, rfGM, gtdN, gtdGM, shselN, shselGM, ilpN, ilpGM, ilpGM2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run():\n",
    "    pres = ['Worm/CE-']\n",
    "    mids = ['BP','MF','CC','BPMF','BPCC','MFCC','BPMFCC']\n",
    "    pro = '.txt'\n",
    "    datasets = []\n",
    "    names = []\n",
    "    for pre in pres:\n",
    "        for mid in mids:\n",
    "            datasets.append(pre + mid + pro)\n",
    "            names.append(pre + mid)\n",
    "    nofsGM, rfN, rfGM, gtdN, gtdGM, shselN, shselGM, ilpN, ilpGM, ilpGM2 = exp(datasets)\n",
    "    df = pd.DataFrame({'Datasets':names,'NOFS_GM':nofsGM, 'ReliefF_N':rfN, 'ReliefF_GM':rfGM, 'GTD_N':gtdN, 'GTD_GM':gtdGM, 'SHSEL_N':shselN, 'SHSEL_GM':shselGM, 'ILP_N':ilpN, 'ILP_GM':ilpGM, 'ILP_GM2':ilpGM2})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = run()\n",
    "df\n",
    "# df.to_csv('result.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
